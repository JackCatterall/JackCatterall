{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpIFDZzV5ML5"
      },
      "source": [
        "# Notation:\n",
        "index: sequence of labels  (are immutable and homogeneous)\n",
        "series: 1d array with index\n",
        "dataframes: 2d array with series as columns, it looks like a relational table, but there's much more. The data frames have\n",
        "    methods which make easier to deal with them. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l5GmHdt_5ML7",
        "outputId": "f66e30c1-a6a9-402e-ec98-7e35852fdef3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     n      d    c\n",
            "country                           \n",
            "US       United States   True  809\n",
            "AU           Australia  False  731\n",
            "JPN              Japan  False  588\n",
            "IND              India  False   18\n",
            "RUS             Russia   True  200\n",
            "MOR            Morocco   True   70\n",
            "EG               Egypt   True   45\n"
          ]
        }
      ],
      "source": [
        "# Pre-defined lists\n",
        "names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
        "dr =  [True, False, False, False, True, True, True]\n",
        "cpc = [809, 731, 588, 18, 200, 70, 45]\n",
        "\n",
        "# Import pandas as pd\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Create dictionary my_dict with three key:value pairs: my_dict\n",
        "my_dict={'n':names,'d':dr,'c':cpc}\n",
        "\n",
        "\n",
        "# Build a DataFrame cars from my_dict: cars\n",
        "cars=pd.DataFrame(my_dict)\n",
        "cars.index = [\"US\", \"AU\", \"JPN\", \"IND\", \"RUS\",\"MOR\",\"EG\"]\n",
        "#or directlu cars=pd.DataFrame(mydict,index=[...])\n",
        "\n",
        "#how to give a general name to the labels of the row:\n",
        "cars.index.name='country'\n",
        "\n",
        "# Print cars\n",
        "print(cars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bstg0A215ML8",
        "outputId": "93bd6853-9e43-42a5-c08b-54078439e8fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 n      d    c\n",
            "US   United States   True  809\n",
            "AUS      Australia  False  731\n",
            "JP           Japan  False  588\n",
            "IN           India  False   18\n",
            "RS          Russia   True  200\n",
            "MR         Morocco   True   70\n",
            "EGT          Egypt   True   45\n"
          ]
        }
      ],
      "source": [
        "#if index is immutable how do i change it?\n",
        "#you must change all the elements in one operation like:\n",
        "cars.index=[\"US\", \"AUS\", \"JP\", \"IN\", \"RS\",\"MR\",\"EGT\"]\n",
        "print(cars) #but note that it deletes also the index.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUlknuRo5ML8"
      },
      "outputs": [],
      "source": [
        "#NOTE: NOW I SHOW HOW TO ACCESS TO DATA CREATING NEW DATA FRAMES THANKS TO THE DOUBLE SQUARE BRACKETS (ALSO IN LOC AND ILOC)\n",
        "#BUT WHEN YOU DON'T WANT A DATAFRAME BUT A PANDASERIES YOU HAVE TO USE ONLY ONE BRACKETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0D91s405ML9",
        "outputId": "b27d9010-9f29-4200-b14c-7d1996862363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 n      d\n",
            "US   United States   True\n",
            "AUS      Australia  False\n",
            "JP           Japan  False\n",
            "IN           India  False\n",
            "RS          Russia   True\n",
            "MR         Morocco   True\n",
            "EGT          Egypt   True\n",
            "             n      d    c\n",
            "AUS  Australia  False  731\n",
            "JP       Japan  False  588\n",
            "IN       India  False   18\n"
          ]
        }
      ],
      "source": [
        "#axessing like a vector but the problem is that row and column indexes are swap:\n",
        "#simple indexing:\n",
        "cars['c']['US'] #note [column][row]!!!\n",
        "\n",
        "#is the same as\n",
        "cars.c['US']\n",
        "\n",
        "# how to have slices of the data frame with brackets (less efficient than using loc and iloc):\n",
        "\n",
        "#columns:\n",
        "print(cars[['n','d']]) #columns are indexed with labels\n",
        "\n",
        "#rows\n",
        "print(cars[1:4])  #rows are indexed with SLICING, not only one number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IOFuh8rh5ML9",
        "outputId": "65f55e61-3874-4470-de62-709729ad9d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 n\n",
            "US   United States\n",
            "AUS      Australia\n",
            "                 n\n",
            "US   United States\n",
            "AUS      Australia\n"
          ]
        }
      ],
      "source": [
        "#how to access with loc(thanks to labels) or iloc(thanks to indexes):\n",
        "\n",
        "#loc:\n",
        "#the advantage with loc is that you can access to rows with labels, and you can select a slice indicating simultaneously\n",
        "#rows and columns:\n",
        "print(cars.loc[['US','AUS'],['n']])   #if you want all the columns or all the rows write cars.loc([:,['n']])\n",
        "\n",
        "#iloc\n",
        "#like lok but instead of labels you write indexes (not slicing!), and you MUST do that for both columns and rows\n",
        "print(cars.iloc[[0,1],[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-48LMo25ML9",
        "outputId": "43bd7e2c-26a8-4a4d-b211-7b0847329ca9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AUS    False\n",
              "JP     False\n",
              "IN     False\n",
              "Name: d, dtype: bool"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#how to do slicing on the panda series:\n",
        "\n",
        "#using normal indexing:\n",
        "cars['n'][1:4]\n",
        "\n",
        "#using loc: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "cars.loc['US':'AUS','n'] #note that it includes also the right extreme of the interval!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "cars.iloc[1:4,1] #this like normal, doesn't include the right extreme.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trycpP7R5ML9",
        "outputId": "0426c683-4b1f-42c3-bf87-f9d5e4cabf31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "US    True\n",
              "RS    True\n",
              "Name: d, dtype: bool"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#selection of columns or rows indicated by a list:\n",
        "cars.loc[['US','AUS'],'n']\n",
        "cars.iloc[[0,4],1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1qrLsmU5ML-",
        "outputId": "08201543-95ba-48ba-bfba-5b099d96a099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "US     809\n",
            "AUS    731\n",
            "JP     588\n",
            "IN      18\n",
            "RS     200\n",
            "MR      70\n",
            "EGT     45\n",
            "Name: c, dtype: int64\n",
            "US      True\n",
            "AUS     True\n",
            "JP      True\n",
            "IN     False\n",
            "RS      True\n",
            "MR     False\n",
            "EGT    False\n",
            "Name: c, dtype: bool\n",
            "                 n      d    c\n",
            "US   United States   True  809\n",
            "AUS      Australia  False  731\n",
            "JP           Japan  False  588\n",
            "RS          Russia   True  200\n"
          ]
        }
      ],
      "source": [
        "#USE OF PANDASERIES:\n",
        "p_s=cars['c']\n",
        "print(p_s)\n",
        "bool_s=p_s>100  \n",
        "print(bool_s)\n",
        "\n",
        "#you can use it to indexing the table, taking only the rows with that attribute >100:\n",
        "print(cars[bool_s])\n",
        "\n",
        "#note that you can directly do this: cars[cars['c']>100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j151JOqt5ML-",
        "outputId": "c2315620-dae8-4c02-b102-a55faf0fd3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         n      d    c\n",
            "JP   Japan  False  588\n",
            "RS  Russia   True  200\n",
            "         n      d    c\n",
            "JP   Japan  False  588\n",
            "RS  Russia   True  200\n"
          ]
        }
      ],
      "source": [
        "#what if I want to do a more advanced selection like the rows with the attribute c greater than 100 and lower than 600?\n",
        "import numpy as np\n",
        "print(cars[np.logical_and(cars['c']>100,cars['c']<600)])\n",
        "#or you can simply do this:\n",
        "print(cars[(cars['c']>100) & (cars['c']<600)])  #note the scheme ()&(), without those parenthesis it doesn't work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgt1WX8A5ML-",
        "outputId": "093021ac-fe65-400f-b24f-f209e10fdbba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-702201933952>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cars.c[cars.d==1]+=1000\n"
          ]
        }
      ],
      "source": [
        "#you can also indexize a column basing on another one like:\n",
        "cars.c[cars.d==1]+=1000\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJV0Yvir5ML-",
        "outputId": "68fd9919-ef39-4084-f524-4d809ed3494e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n\n",
            "d\n",
            "c\n",
            "\n",
            "\n",
            "US  :  2809\n",
            "AUS  :  731\n",
            "JP  :  588\n",
            "IN  :  18\n",
            "RS  :  2200\n",
            "MR  :  2070\n",
            "EGT  :  2045\n"
          ]
        }
      ],
      "source": [
        "#iterating in data frames:\n",
        "for what in cars:   #it prints only the column labels!\n",
        "    print(what)  \n",
        "\n",
        "print('\\n')\n",
        "    \n",
        "# like with dictionaries for k,v in D.items() we have to do  for row_label,row_data in cars.iterrows()\n",
        "for row_label,row_data in cars.iterrows():\n",
        "    print(row_label,' : ',row_data['c']) \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuqvR1Ez5ML_",
        "outputId": "f3005a1f-e66b-4594-855b-85004418d107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 n      d     c new_column_label\n",
            "US   United States   True  2809        new_value\n",
            "AUS      Australia  False   731        new_value\n",
            "JP           Japan  False   588        new_value\n",
            "IN           India  False    18        new_value\n",
            "RS          Russia   True  2200        new_value\n",
            "MR         Morocco   True  2070        new_value\n",
            "EGT          Egypt   True  2045        new_value\n",
            "                 n      d     c new_column_label  new_column_label2\n",
            "US   United States   True  2809        new_value                 13\n",
            "AUS      Australia  False   731        new_value                  9\n",
            "JP           Japan  False   588        new_value                  5\n",
            "IN           India  False    18        new_value                  5\n",
            "RS          Russia   True  2200        new_value                  6\n",
            "MR         Morocco   True  2070        new_value                  7\n",
            "EGT          Egypt   True  2045        new_value                  5\n"
          ]
        }
      ],
      "source": [
        "#how to add a column in a not efficient way (it creates series at each iteration:\n",
        "\n",
        "for label,row_data in cars.iterrows():\n",
        "    cars.loc[label,'new_column_label']='new_value'\n",
        "print(cars)\n",
        "\n",
        "\n",
        "#a more efficient way: using the function apply, for instance if the new column is the result of the application of\n",
        "#a function to another column:\n",
        "\n",
        "cars['new_column_label2']=cars[\"n\"].apply(len) #if you need to iterate on other rows\n",
        "print(cars)\n",
        "\n",
        "#or simply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzhcT50N5ML_",
        "outputId": "e27e7b5f-c1ae-4707-e9d6-6f5e4430f9cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 n      d     c new_column_label  new_column_label2  some_zero\n",
            "US   United States   True  2809        new_value                 13          0\n",
            "AUS      Australia  False   731        new_value                  9          0\n",
            "JP           Japan  False   588        new_value                  5          1\n",
            "IN           India  False    18        new_value                  5          2\n",
            "RS          Russia   True  2200        new_value                  6          3\n",
            "MR         Morocco   True  2070        new_value                  7          4\n",
            "EGT          Egypt   True  2045        new_value                  5          5\n"
          ]
        }
      ],
      "source": [
        "cars['some_zero']=[0,0,1,2,3,4,5]\n",
        "print(cars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW4bWa0m5ML_",
        "outputId": "a1ed92cc-123d-40c3-802d-f497eb5ae241"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "US     561\n",
              "AUS    146\n",
              "JP     117\n",
              "IN       3\n",
              "RS     440\n",
              "MR     414\n",
              "EGT    409\n",
              "Name: c, dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#vectorization:\n",
        "\n",
        "#example of a fucntion applied to all a column (but you can do it also to all the dataframe) without loops:\n",
        "cars.c.floordiv(10)\n",
        "\n",
        "#or if you want to apply a function created from you:\n",
        "def floo(n):\n",
        "    return n//10\n",
        "    \n",
        "cars.c.apply(floo) #note that you don't write the input of the function because the apply function puts the element of the column\n",
        "#as input.\n",
        "\n",
        "#you can do the same thing defining directly (and locally) a function thanks to the keyword lambda:\n",
        "cars.c.apply(lambda n: n//5)\n",
        "\n",
        "#apply is not applable to the index!!! you must use map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSG6xKYD5ML_",
        "outputId": "364ffd4e-0075-4dee-ff53-c8ee5d3ebfc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['US', 'AUS', 'JP', 'IN', 'RS', 'MR', 'EGT'], dtype='object')\n",
            "                 n      d     c new_column_label  new_column_label2  some_zero\n",
            "us   United States   True  2809        new_value                 13          0\n",
            "aus      Australia  False   731        new_value                  9          0\n",
            "jp           Japan  False   588        new_value                  5          1\n",
            "in           India  False    18        new_value                  5          2\n",
            "rs          Russia   True  2200        new_value                  6          3\n",
            "mr         Morocco   True  2070        new_value                  7          4\n",
            "egt          Egypt   True  2045        new_value                  5          5\n",
            "Index(['US', 'AUS', 'JP', 'IN', 'RS', 'MR', 'EGT'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#operation on strings:\n",
        "print(cars.index) #it contains a vector of strings.\n",
        "#to work on strings we need this kind of syntex:\n",
        "#cars.index.str.lower() \n",
        "#so to modify all the labels:\n",
        "cars.index=cars.index.str.lower()\n",
        "print(cars)\n",
        "\n",
        "\n",
        "# for the index we must use map instead of apply with a little different syntax:\n",
        "print(cars.index.map(str.upper))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pmf5jLm5ML_",
        "outputId": "8f95cff1-ee34-4814-a972-c44b64c41091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 n      d     c new_column_label  new_column_label2  some_zero\n",
            "us   United States   True  2809        new_value                 13        NaN\n",
            "aus      Australia  False   731        new_value                  9        NaN\n",
            "jp           Japan  False   588        new_value                  5        1.0\n",
            "in           India  False    18        new_value                  5        2.0\n",
            "rs          Russia   True  2200        new_value                  6        3.0\n",
            "mr         Morocco   True  2070        new_value                  7        4.0\n",
            "egt          Egypt   True  2045        new_value                  5        5.0\n",
            "\n",
            " n                     True\n",
            "d                    False\n",
            "c                     True\n",
            "new_column_label      True\n",
            "new_column_label2     True\n",
            "some_zero             True\n",
            "dtype: bool\n",
            "\n",
            "                  n     c new_column_label  new_column_label2  some_zero\n",
            "us   United States  2809        new_value                 13        NaN\n",
            "aus      Australia   731        new_value                  9        NaN\n",
            "jp           Japan   588        new_value                  5        1.0\n",
            "in           India    18        new_value                  5        2.0\n",
            "rs          Russia  2200        new_value                  6        3.0\n",
            "mr         Morocco  2070        new_value                  7        4.0\n",
            "egt          Egypt  2045        new_value                  5        5.0\n",
            "                 n      d     c new_column_label  new_column_label2  some_zero\n",
            "us   United States   True  2809        new_value                 13        NaN\n",
            "aus      Australia  False   731        new_value                  9        NaN\n",
            "jp           Japan  False   588        new_value                  5        1.0\n",
            "in           India  False    18        new_value                  5        2.0\n",
            "rs          Russia   True  2200        new_value                  6        3.0\n",
            "mr         Morocco   True  2070        new_value                  7        4.0\n",
            "egt          Egypt   True  2045        new_value                  5        5.0\n"
          ]
        }
      ],
      "source": [
        "#how to select only columns which have ALL NON ZERO VALUES:\n",
        "\n",
        "#let's add a column with some zero before:\n",
        "cars['some_zero']=[None,None,1,2,3,4,5]\n",
        "#print(cars)\n",
        "print(cars)\n",
        "print('\\n',cars.all())  #note that also false value are considered as zeros.\n",
        "#so let's select only the rows without zeros  (Nona/Nan instead is not considered as a zero!)\n",
        "print('\\n',cars.loc[:,cars.all()])\n",
        "\n",
        "#or in the opposite we may ask the columns with ANY NON ZERO values, so in this case all the dataframe:\n",
        "print(cars.loc[:,cars.any()]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_KVNmyx5ML_",
        "outputId": "41b3694a-618b-4c6d-e493-115ef3b030b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     some_zero\n",
            "us         NaN\n",
            "aus        NaN\n",
            "jp         1.0\n",
            "in         2.0\n",
            "rs         3.0\n",
            "mr         4.0\n",
            "egt        5.0\n",
            "                 n      d     c new_column_label  new_column_label2\n",
            "us   United States   True  2809        new_value                 13\n",
            "aus      Australia  False   731        new_value                  9\n",
            "jp           Japan  False   588        new_value                  5\n",
            "in           India  False    18        new_value                  5\n",
            "rs          Russia   True  2200        new_value                  6\n",
            "mr         Morocco   True  2070        new_value                  7\n",
            "egt          Egypt   True  2045        new_value                  5\n",
            "           n      d     c new_column_label  new_column_label2  some_zero\n",
            "jp     Japan  False   588        new_value                  5        1.0\n",
            "in     India  False    18        new_value                  5        2.0\n",
            "rs    Russia   True  2200        new_value                  6        3.0\n",
            "mr   Morocco   True  2070        new_value                  7        4.0\n",
            "egt    Egypt   True  2045        new_value                  5        5.0\n"
          ]
        }
      ],
      "source": [
        " #how to ask if the dataframe has any Nan value?\n",
        "print(cars.loc[:,cars.isnull().any()])\n",
        "\n",
        "#how to ask all columns which DON'T HAVE Nan:\n",
        "print(cars.loc[:,cars.notnull().all()])\n",
        "\n",
        "#we can also remove the rows with some Nan:\n",
        "print(cars.dropna(how='any'))   #note that it doesn't modifies the old dataframe, it return a new one (if you do print(cars)\n",
        "#you see that isn't changed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX_-deQJ5MMA",
        "outputId": "82f3bf0e-2e3f-4c72-edc8-c70dbfb69330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       d     c new_column_label  new_column_label2  some_zero\n",
            "n                                                                            \n",
            "United States us    True  2809        new_value                 13        NaN\n",
            "Australia     aus  False   731        new_value                  9        NaN\n",
            "Japan         jp   False   588        new_value                  5        1.0\n",
            "India         in   False    18        new_value                  5        2.0\n",
            "Russia        rs    True  2200        new_value                  6        3.0\n",
            "Morocco       mr    True  2070        new_value                  7        4.0\n",
            "Egypt         egt   True  2045        new_value                  5        5.0\n",
            "\n",
            "\n",
            "None\n",
            "['n', None]\n"
          ]
        }
      ],
      "source": [
        "#for some reason can be useful to have an index made of two values/labels or more, so:\n",
        "cars=cars.set_index(['n',cars.index]) #for instance i can use the old index and also the column n to became the new index.\n",
        "print(cars)\n",
        "\n",
        "#note this:\n",
        "print('\\n')\n",
        "print(cars.index.name)\n",
        "print(cars.index.names)\n",
        "\n",
        "\n",
        "#now that you have more than one index you can play with it: in cases in which one of the two indexes is repeated, if you\n",
        "#index just it so it's like doing a slicing on the other one automatically because you select more rows.\n",
        "\n",
        "#fancy indexing in case or more indexes, look at it if needed: Manipulating DataFrames with pandas->Advanced indexing->hierarchical indexing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZC0nfHO5MMA",
        "outputId": "2c1c7a73-4c3c-433d-a65f-03e58f676dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       d     c new_column_label  new_column_label2  some_zero\n",
            "n                                                                            \n",
            "Australia     aus  False   731        new_value                  9        NaN\n",
            "Egypt         egt   True  2045        new_value                  5        5.0\n",
            "India         in   False    18        new_value                  5        2.0\n",
            "Japan         jp   False   588        new_value                  5        1.0\n",
            "Morocco       mr    True  2070        new_value                  7        4.0\n",
            "Russia        rs    True  2200        new_value                  6        3.0\n",
            "United States us    True  2809        new_value                 13        NaN\n"
          ]
        }
      ],
      "source": [
        "#how to sort a dataframe basing on the index:\n",
        "print(cars.sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECSh4ANl5MMA",
        "outputId": "0443b36f-9351-4cb0-9db7-8084093077f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gender     F  M\n",
            "treatment      \n",
            "A          5  3\n",
            "B          8  9\n",
            "          id    response   \n",
            "gender     F  M        F  M\n",
            "treatment                  \n",
            "A          1  2        5  3\n",
            "B          3  4        8  9\n",
            "          id    response   \n",
            "gender     F  M        F  M\n",
            "treatment                  \n",
            "A          1  2        5  3\n",
            "B          3  4        8  9\n",
            "                  id  response\n",
            "treatment gender              \n",
            "A         F        1         5\n",
            "          M        2         3\n",
            "B         F        3         8\n",
            "          M        4         9\n",
            "                  id  response\n",
            "gender treatment              \n",
            "F      A           1         5\n",
            "M      A           2         3\n",
            "F      B           3         8\n",
            "M      B           4         9\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <th>treatment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">F</th>\n",
              "      <th>A</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">M</th>\n",
              "      <th>A</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  response\n",
              "gender treatment              \n",
              "F      A           1         5\n",
              "       B           3         8\n",
              "M      A           2         3\n",
              "       B           4         9"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "trials=pd.DataFrame({'id':[1,2,3,4],'treatment':['A','A','B','B'],'gender':['F','M','F','M'],'response':[5,3,8,9]})\n",
        "\n",
        "#reshape a dataframe with the function 'pivot:\n",
        "print(trials.pivot(index='treatment',columns='gender',values='response'))\n",
        "#or if you don't speciy the values, it will be all the remanent columns\n",
        "print(trials.pivot(index='treatment',columns='gender'))\n",
        "#but pivoting requires unique column pairs to identify values in the new value. the solution: pivot_table\n",
        "\n",
        "\n",
        "#another way to obtain it:\n",
        "trials=trials.set_index(['treatment','gender'])\n",
        "print(trials.unstack(level='gender')) \n",
        "#the column specified is the one to be moved to the index\n",
        "#the difference is that this one gives an hierarchical indexing in general.\n",
        "#or you could use integer indexing: print(trials.unstack(level=1))\n",
        "\n",
        "#the method stack does the opposite\n",
        "\n",
        "\n",
        "#but i obtain a hierarchical indexing, what if I want to change it?\n",
        "print(trials)\n",
        "print(trials.swaplevel(0,1))\n",
        "#then you can sort it:\n",
        "trials.swaplevel(0,1).sort_index()\n",
        "\n",
        "#see the method 'melt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvBUpysb5MMA"
      },
      "source": [
        "# MACHINE LEARNING LABS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb_EBIw85MMA",
        "outputId": "86bd6e64-c358-40a1-c050-26925404b384"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-30-a08287f95b8d>, line 45)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-30-a08287f95b8d>\"\u001b[1;36m, line \u001b[1;32m45\u001b[0m\n\u001b[1;33m    dataset=pd.read_csv('wine.data',sep=',',names=[list of names to give to the columns]) #by default the separator is ','\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#learnt in labs:\n",
        "\n",
        "help(name_function) # to have informations!!\n",
        "\n",
        "###########\n",
        "#typical imports:\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, silhouette_score, silhouette_samples\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, ParameterGrid\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#useful staff:\n",
        "\n",
        "#transform something in a dataframe:\n",
        "df = pd.DataFrame(dictionary)\n",
        "\n",
        "# set random state:\n",
        "random_state = 15\n",
        "np.random.seed(random_state)\n",
        "\n",
        "#import a file from the same folder\n",
        "dataset=pd.read_csv('wine.data',sep=',',names=[list of names to give to the columns]) #by default the separator is ','\n",
        "#if it is from another folder put the whole path, using / instead of \\.\n",
        "\n",
        "#import as text file\n",
        "data_file = 'ex1_4dim_data.csv'\n",
        "X = np.loadtxt(data_file, delimiter = ',')\n",
        "\n",
        "#import from the web:\n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "dataset = pd.read_csv(url, sep = ';')\n",
        "\n",
        "#import data from another folder:\n",
        "dataset=sns.load_dataset('C:/Users/97and/OneDrive/Desktop/machine learning/lab/lab2_decisiontree/ml_03-01-intro-iris/ml_03-01-intro-iris/data/iris'\\,\n",
        "                        names=[list of names to give to the columns])\n",
        "\n",
        "\n",
        "\n",
        "#############\n",
        "#look the data:\n",
        "\n",
        "dataset.columns # it shows the column names\n",
        "dataset.dtypes #type of each column\n",
        "dataset.head(n) #remember the parenthesis! it create a beauteful view of the data in a table visualizing only the first n rows\n",
        "dataset.index\n",
        "dataset.values\n",
        "dataset.index.names\n",
        "dataset['name_column'].value_counts()\n",
        "dataset['new_column']=vector\n",
        "# look the class names, in order and without repetition:\n",
        "df[target_name].unique()\n",
        "classes.sort()\n",
        "# sort following the index:\n",
        "dataset.sort_index(ascending=1 or 0)\n",
        "\n",
        "\n",
        "#####histogram:\n",
        "\n",
        "#histogram for only one column, with numeric values:\n",
        "plt.hist(dataset['name_column']);  #remember the semicolumn ';' to avoid outoput of some properties of the histogram.\n",
        "\n",
        "#histogram for only one column, with strings:\n",
        "dataset['name_column'].value_counts().plot(kind = 'bar')\n",
        "\n",
        "#histogram for all the columns with numeric values all together:\n",
        "pd.DataFrame.hist(dataset, figsize = [15,15]);\n",
        "\n",
        "\n",
        "####### statistic:\n",
        "dataset.describe() #it computes all the useful statistic (only of the numeric columns\n",
        "dataset['name_column'].describe()#to apply it only to one 'target column'\n",
        "\n",
        "\n",
        "########## boxplot:\n",
        "#https://seaborn.pydata.org/generated/seaborn.boxplot.html  for info about it\n",
        "\n",
        "import seaborn as sns\n",
        "sns.boxplot(dataset['attribute1'],dataset['attribute2']) # to do it only of a column or column vs column\n",
        "df.boxplot() # to do it of any columns in the same plot\n",
        "\n",
        "#if you don't see the box look with describe the column: probably all the values are close to zero\n",
        "# you see that beacuse the mean has a low value and the 25%,50% and 75% are all =0.\n",
        "#solution: (use the np.log10 to see it after adding 1)\n",
        "\n",
        "from numpy import log10\n",
        "sns.boxplot(log10(dataset['attribute1']+1), dataset['attribute2'])\n",
        "#if the values are not close to zero but exactly zero, you won't see the boxplot anyway.\n",
        "#if ypu want to see the boxplot excluding them:\n",
        "sns.boxplot(dataset['attribute1']!=0, dataset['attribute2'])\n",
        "\n",
        "\n",
        "#### pairplot:\n",
        "sns.pairplot(dataset, hue='class_column_name', height=2);\n",
        "\n",
        "# scatter plot\n",
        "plt.scatter(dataset['attribute1'],dataset['attribute2'])\n",
        "\n",
        "#typical commands for plots:\n",
        "plt.figure(figsize=[10,10])\n",
        "plt.grid()  # plots a grid on the data\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq1P9WpJ5MMA",
        "outputId": "890d7599-6769-424e-b80a-e462003676ee"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-31-4b2ffc4e5519>, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-4b2ffc4e5519>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    DO THE TRANSFORMATION ONLY IF THE PROBLEM OF SCALE IS BETWEEN THE ATTRIBUTES OF INTEREST\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# PREPROCESSING:\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "#DO THE TRANSFORMATION ONLY IF THE PROBLEM OF SCALE IS BETWEEN THE ATTRIBUTES OF INTEREST\n",
        "\n",
        "\n",
        "\n",
        "tumor_size_dict = dict(zip(list(df['tumor-size'].unique()),list(df['tumor-size'].unique())))\n",
        "df['tumor-size'] = df['tumor-size'].map(tumor_size_dict)\n",
        "\n",
        "\n",
        "categorical_features = df.dtypes.loc[df.dtypes == 'object'].index.values\n",
        "print(\"The non-numeric features are:\")\n",
        "print(categorical_features)\n",
        "\n",
        "numeric_features = list(set(df.dtypes.index.values)-set(categorical_features))\n",
        "print(\"The numeric features are:\")\n",
        "print(numeric_features)\n",
        "\n",
        "ordinal_features =['age', 'tumor-size','inv-nodes']\n",
        "print(\"The ordinal features are:\")\n",
        "print(ordinal_features)\n",
        "\n",
        "categorical_features = list(set(categorical_features) - set(ordinal_features) - set(['Class']))\n",
        "print(\"The categorical features are:\")\n",
        "print(categorical_features)\n",
        "\n",
        "\n",
        "\n",
        "OHE=OneHotEncoder(sparse=False,dtype=np.int32,handle_unknown='ignore')\n",
        "ORE=OrdinalEncoder(dtype=np.int32)\n",
        "\n",
        "preprocessor=ColumnTransformer(\n",
        "                   transformer= [('categ',OHE,columns_categ),('ordinal',ORE,columns_ordinal)],remainder='passthrough')\n",
        "\n",
        "#fit\n",
        "preprocessor.fit(X)\n",
        "#fit transform\n",
        "X_processed = preprocessor.fit_transform(X)      # note that fit and fit_transform are methods, not functions!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkfVT5oo5MMB",
        "outputId": "2d1abb90-dce4-41dd-e28f-90f3b77a4476"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'algorithm' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-32-98706be03ecb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m########## supervised learning:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'algorithm' is not defined"
          ]
        }
      ],
      "source": [
        "########## supervised learning:\n",
        "model=algorithm\n",
        "model.fit(X,y)\n",
        "y_pred=model.predict(X)\n",
        "\n",
        "#### preparing data:\n",
        "\n",
        "# divide all columns=X   vs   target column=y\n",
        "X = dataset.drop('classes_column', axis=1)\n",
        "y= dataset['classes_column']\n",
        "\n",
        "\n",
        "\n",
        "#if the dataset is taken from sklearn libraries:\n",
        "X=dataset.data\n",
        "y=dataset.target\n",
        "# divide in test and training set\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=1)\n",
        "\n",
        "\n",
        "######## classifier: decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier       # 1. choose model class\n",
        "model = DecisionTreeClassifier(criterion = 'entropy',max_depth=3) # 2. instantiate model and set the hyperparameters\n",
        "model.fit(Xtrain, ytrain)                             # 3. fit model to data\n",
        "y=model.predict(Xtrain)                               # 4. predict labels\n",
        "\n",
        "\n",
        "#accuracy:\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "####### training error:\n",
        "ytrain_pred = model.predict(Xtrain)                  # 4. use the model on training data\n",
        "accuracy_train = accuracy_score(ytrain, ytrain_pred)\n",
        "\n",
        "####### test error\n",
        "ytest_pred = model.predict(Xtest)                  # 5. use the model on new data\n",
        "accuracy_test = accuracy_score(ytest, ytest_pred)\n",
        "\n",
        "#the function simply does this:\n",
        "accuracy_train = np.mean(y_train == y_predicted_train) * 100\n",
        "\n",
        "# recall, precision etc:\n",
        "print(classification_report(y_test, y_predicted))\n",
        "\n",
        "#conf matrix:\n",
        "print(confusion_matrix(y_test, y_predicted))\n",
        "\n",
        "\n",
        "\n",
        "# hyperparamiter regularization, using simply for of validations:\n",
        "\n",
        "scores = []\n",
        "for par in parameter_values:\n",
        "    estimator = tree.DecisionTreeClassifier(criterion=\"entropy\"\n",
        "                                            , max_depth = par\n",
        "                                           )\n",
        "    estimator.fit(X_train_t, y_train_t)\n",
        "    y_predicted_val = estimator.predict(X_val)\n",
        "    score =  accuracy_score(y_val, y_predicted_val) * 100 # compute the matches between prediction and true classes\n",
        "    scores.append(score)\n",
        "\n",
        "plt.figure(figsize=(32,20))\n",
        "plt.plot(parameter_values, scores, '-o', linewidth=5, markersize=24)\n",
        "plt.xlabel('max_depth')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title(\"Score with validation varying max_depth of tree\", fontsize = 24)\n",
        "plt.show();\n",
        "\n",
        "\n",
        "# hyperparamiter regularization, using for of crossvalidation (which is itself for of validations)\n",
        "avg_scores = []\n",
        "for par in parameter_values:\n",
        "    estimator = tree.DecisionTreeClassifier(criterion=\"entropy\"\n",
        "                                            , max_depth = par\n",
        "                                            )\n",
        "    scores = cross_val_score(estimator, X_train, y_train\n",
        "                             , scoring='accuracy', cv = 5)  \n",
        "    # cross_val_score produces an array with one score for each fold\n",
        "    avg_scores.append(np.mean(scores))\n",
        "print(avg_scores)\n",
        "\n",
        "# take the best parameter:\n",
        "top_par = parameter_values[np.argmax(scores)]\n",
        "\n",
        "\n",
        "#ensemble method: bagging\n",
        "estimator_bagging = BaggingClassifier(tree.DecisionTreeClassifier(criterion=\"entropy\"\n",
        "                                             , max_depth = par)\n",
        "                                          , max_samples=0.5\n",
        "                                          , max_features=0.5\n",
        "                                         )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print with format:\n",
        "print(\"Simple HoldOut and full tree        :   {:.1f}%      {}\".format(accuracy_ho, fitted_max_depth))\n",
        "\n",
        "\n",
        "\n",
        "# GRIDSEARCH:\n",
        "# input example:\n",
        "param_svc = [{'kernel': ['rbf'], \n",
        "                    'gamma': [1e-3, 1e-4],\n",
        "                    'C': [1, 10, 100, 1000],\n",
        "                    },\n",
        "                    {'kernel': ['linear'],\n",
        "                     'C': [1, 10, 100, 1000],                     \n",
        "                    },\n",
        "                   ]\n",
        "#use of grid search:\n",
        "clf = GridSearchCV(SVC(), param_svc , cv=5,\n",
        "                     scoring=precision_macro,  \n",
        "                     iid = False, \n",
        "                     return_train_score = False,\n",
        "                     n_jobs = 2, # this allows using multi-cores\n",
        "                           )\n",
        "\n",
        "clf.best_score_\n",
        "clf.best_params_\n",
        "clf.cv_results_['mean_test_score']\n",
        "clf.cv_results_['std_test_score']\n",
        "clf.cv_results_['params']\n",
        "clf.classes_\n",
        "\n",
        "\n",
        "\n",
        "######## DECISION TREE:\n",
        "#model:\n",
        "from sklearn.tree import DecisionTreeClassifier       # 1. choose model class\n",
        "model = DecisionTreeClassifier(criterion = 'entropy') # 2. instantiate model and set the hyperparameters\n",
        "\n",
        "#visualize it:\n",
        "from matplotlib import pyplot\n",
        "from sklearn.tree import plot_tree\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "plot_tree(model\n",
        "#          , fontsize=6\n",
        "          , filled=True\n",
        "          , feature_names = X.columns\n",
        "          , class_names = str(model.classes_)\n",
        "          , rounded = True\n",
        "          , proportion = True\n",
        "          , rotate = False\n",
        "         ); \n",
        "\n",
        "# feature_names and class_names must be in alphabetic order. you can use this function to do it: \n",
        "class_names2pass=sorted(y.unique()) # or directly give as input str(model.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGjCCWm5MMB"
      },
      "outputs": [],
      "source": [
        "#UNSUPERVISED:   \n",
        "cl=algorithm()\n",
        "labels=cl.fit_predict(dataset)\n",
        "\n",
        "#usually the array is a fucking array! you can't use all the dataframe methods.\n",
        "\n",
        "#kmeans\n",
        "distortions = []    # also called inertia_ !!!!\n",
        "silhouette_scores = []\n",
        "for i in k_range:\n",
        "    km = KMeans(n_clusters=i, \n",
        "                init='k-means++', \n",
        "                n_init=10, \n",
        "                max_iter=300, \n",
        "                random_state=rnd_state)\n",
        "    y_km = km.fit_predict(X)\n",
        "    distortions.append(km.inertia_)        # note that the inertia_ is an attribute of the model!!\n",
        "    silhouette_scores.append(silhouette_score(X,y_km))    # of course as input is needed the whole dataset and the labels assigned by your clastering scheme.\n",
        "    \n",
        "plot_clusters(X,y_km,dim=(focus[0],focus[1]), points = km.cluster_centers_)  # this is a function given by the prfessor\n",
        "print('Distortion: %.2f' % km.inertia_)\n",
        "\n",
        "#evaluation of the clusters\n",
        "cluster_labels = np.unique(y_km)\n",
        "n_clusters = cluster_labels.shape[0] # it is the number of rows\n",
        "\n",
        "# Compute the Silhouette Coefficient for each sample, with the euclidean metric\n",
        "silhouette_score_samples = silhouette_samples(X, y_km, metric='euclidean')\n",
        "plot_silhouette(silhouette_score_samples, y_km)  \n",
        "# THIS IS NOT THE PLOT TO BE USED TO FIND THE BEST K! BUT IS NEEDED TO COMPARE CLUSTERING SCHEME.\n",
        "#anyway is a function given by the professor.\n",
        "\n",
        "\n",
        "#DBSCAN\n",
        "db = DBSCAN()\n",
        "y_db = db.fit_predict(X)\n",
        "\n",
        "\n",
        "\n",
        "#it's parameters are eps=radious to define the neighb. and MinPoints to define if an object is core or border.\n",
        "\n",
        "#if there are labels=-1 those are noise!! Use the method unique to help you find them.\n",
        "\n",
        "#compute centers, unlike kmeans which are given doing km.cluster_centers_\n",
        "\n",
        "#cluster_centers = np.empty((n_clusters,X.shape[1]))  #if you want to pre-create the array.\n",
        "for i in cluster_labels:\n",
        "    cluster_centers[i,:] = np.mean(X[y_db==i,:], axis = 0) #the mean of all the values of that cluster, in vertical direction! \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYlOZjMY5MMB"
      },
      "outputs": [],
      "source": [
        "#other staff:\n",
        "\n",
        "#zip([1,2,3],[a,b,c])-> ((1,a),(2,b),(3,c))\n",
        "#map(sqrt(),[1,2,3])  the output is a map object, converti it in list or set\n",
        "#df.map(dictionary)   is going to substitute to all the value='key of the dictionary' a value ='value of the dictionary'\n",
        "\n",
        "\n",
        "#use the function ParameterGrid to have all the combinations of the dictionary values that you give him.\n",
        "params = list(ParameterGrid({'eps': list(np.arange(0.05, 1, 0.05)), 'min_samples': list(range(1,10,1))}))  \n",
        "#remember to convert the result in a list.\n",
        "\n",
        "\n",
        "for i in range(len(params)):\n",
        "    db = DBSCAN(**(params[i]))   # it must be passed as input in this way.\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "#visualize them         \n",
        "print(\"Rows with missing InvoiceNo before removing\")\n",
        "df1[df1['Attribute'].isna()]   # the ones which are NaN in that column\n",
        "#remove them:\n",
        "df2 = df1.dropna(axis=0, subset=['InvoiceNo'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}